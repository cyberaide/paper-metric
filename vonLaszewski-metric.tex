\documentclass{sig-alternate} 

\newcommand{\TITLE}{Towards Understanding Cloud Usage with Measuring Resource Allocation}
\newcommand{\AUTHOR}{Hyungro Lee, Gregor von Laszewski, Fugang Wang} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% LATEX DEFINITIONS 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{hyperref} 
\usepackage{array} 
\usepackage{graphicx} 
\usepackage{booktabs} 
\usepackage{pifont} 
\usepackage{todonotes} 
\usepackage{rotating} 
\usepackage{color} 
\usepackage{listings}
 
\newcommand*\rot{\rotatebox{90}} 
 
\newcommand{\FILE}[1]{\todo[color=green!40]{#1}} 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% HYPERSETUP 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hypersetup{ 
    bookmarks=true,         % show bookmarks bar 
    unicode=false,          % non-Latin characters in Acrobat’s bookmarks 
    pdftoolbar=true,        % show Acrobat’s toolbar 
    pdfmenubar=true,        % show Acrobat’s menu 
    pdffitwindow=false,     % window fit to page when opened 
    pdfstartview={FitH},    % fits the width of the page to the window 
    pdftitle={\TITLE},    % title 
    pdfauthor={\AUTHOR},     % author 
    pdfsubject={Subject},   % subject of the document 
    pdfcreator={Gregor von Laszewski, Fugang Wang},   % creator of the document 
    pdfproducer={Gregor von Laszewski}, % producer of the document 
    pdfkeywords={hindex} {metric}{XSEDE} {FutureGrid}, % list of keywords 
    pdfnewwindow=true,      % links in new window 
    colorlinks=false,       % false: boxed links; true: colored links 
    linkcolor=red,          % color of internal links (change box color with linkbordercolor) 
    citecolor=green,        % color of links to bibliography 
    filecolor=magenta,      % color of file links 
    urlcolor=cyan           % color of external links 
} 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\lstset{frame=tb,
language=sh,
aboveskip=3mm,
belowskip=3mm,
showstringspaces=false,
columns=flexible,
basicstyle={\scriptsize\ttfamily},
numbers=none,
numberstyle=\tiny\color{gray},
keywordstyle=\color{blue},
commentstyle=\color{dkgreen},
stringstyle=\color{mauve},
breaklines=true,
breakatwhitespace=true
tabsize=3
}
\begin{document} 
% 
% --- Author Metadata here --- 
\conferenceinfo{TBD}{TBD Address} 
\CopyrightYear{2014}  
\crdata{X-XXXXX-XX-X/XX/XX}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE. 
% --- End of Author Metadata --- 
 
\title{\TITLE} 
%\subtitle{[Extended Abstract] 
%\titlenote{A full version of this paper is available as 
%\texttt{www.acm.org/eaddress.htm}}} 
 
\numberofauthors{4}  
\author{ 
\alignauthor 
Hyungro Lee\\ 
       \affaddr{Indiana University}\\ 
       \affaddr{2719 10th Street}\\ 
       \affaddr{Bloomington, Indiana, U.S.A.}\\ 
\alignauthor 
Gregor von Laszewski\titlenote{Corresponding Author.}\\ 
       \affaddr{Indiana University}\\ 
       \affaddr{2719 10th Street}\\ 
       \affaddr{Bloomington, Indiana, U.S.A.}\\ 
       \email{laszewski@gmail.com} 
\alignauthor 
Fugang Wang\\ 
       \affaddr{Indiana University}\\ 
       \affaddr{2719 10th Street}\\ 
       \affaddr{Bloomington, Indiana, U.S.A.}\\ 
% 3rd. author 
\and
\alignauthor 
Geoffrey C. Fox\\ 
       \affaddr{Indiana University}\\ 
       \affaddr{2719 10th Street}\\ 
       \affaddr{Bloomington, Indiana, U.S.A.}\\ 
\and  % use '\and' if you need 'another row' of author names 
} 
\date{13 March 2014} 
 
\toappear{} 
\maketitle 
\begin{abstract} 

In utility computing, usage data is necessary to identify utilization of the infrastructure by users. Many cloud platforms recently started to collect measurements for use of resources that can be applied to billing and monitoring. The usage data allows a user to see as how all resources are efficiently supplied to their applications and discover usage pattern in historical data. Virtual resources such as compute, storage and network are typically measured to evaluate time and cost of user applications and the statistics for resource used offer visibility to utilization of the cloud.

\end{abstract} 
 
% A category with the (minimum) three required fields 
\category{H.4}{Information Systems Applications}{Miscellaneous} 
%A category including the fourth, optional field follows... 
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures] 
 
\terms{Theory} 
 
\keywords{Scientific impact, bibliometric, h-index, Technology audit, XSEDE} 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% SECTIONS 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 
\section{Introduction} 

\subsection{Background}
In distributed systems and HPC, resource usage are typically monitored to detect any hardware and software issues. Real-time monitoring applications help provide sustain and consistent services and engage performance of their system. Distributed systems were built with complex hardwares and require to incorporate with various hardwares such as router, switch, network, and servers along with computing resources like cpu, memory and disk. In Cloud Computing, people have attention to monitoring and accounting systems in virtualized environments, so that they can measure resource consumption which is what they are paying for on the on-demand service, cloud computing. 

Many places now adopt virtualization and cloud services to enhance the capacity of their system infrastructure and performance. Performance management is getting more important in this regard for identifying and delivering reasonable resource allocation. But traditional performance software are still designed to measure a certain type of resources and system administrators raised needs for a unified performance management with virtual resource allocation which provides a bird eye's view to monitor system utilization with the proper provision and allocation of resources [1]. The unified monitoring software is not only about an integrating metric units and aggregating numerical values but also about making sure that the applications on the services are efficiently consuming allocated resources and the resources are properly allocated in the right place at the right time. Understanding system utilization and application performance with the observation from the software is important to satisfy service-level agreements (SLAs) and improve the system administration, however in a virtualized environment, measuring shared resources is not an easy task since they are in multiple points and different layers. 

\subsection{Real Consumption vs Allocation}
There are two types of measuring resource usage on the cloud. Like a conventional monitoring, resource consumption on the cloud is based on current usage data for cpu, memory, network and disk traffics. These are dynamically changing according to traffics, and are important to validate system health frequently. The other type of measuring resource usage is measuring the amount of allocated resources. It is an accounting system that records allocation of resources. In a shared resource environment which is a fundamental concept in utility computing, the amount of allocated resource means that your requested resource will be dominated to you not interrupted by any other users. Resource allocation is not measuring real-time resource usage. Instead, it records rented resources in an accounting book for billing and charging. There are static metrics for allocation such as allocated number of cpu cores, memories, and disks. Number of public IP addresses is also counted for metrics.

\subsection{Motivation}

Investigation for performance managements on the cloud would provide understanding of resource usage and statistics in several ways such as accounting/billing and provisioning. This classification will help evaluate the current performance of the cloud systems and gain the visibility of resource utilization across application layer and system layer. 

\subsection{Problem}

Cloud platform relies on sharing of computing and storage resources with many people like a public utility, understanding amounts of the usage of resources is getting important to the cloud users and cloud providers. It is not only important measuring use of resources but also important displaying metrics via graphical charts. There are concrete challenges for this research area: 

Understanding - it is a basic functionality to see how reliable the system is and to prevent system failures by knowing the resource utilization. It also gives an opportunity to manage the system efficiently by knowing the performance of the system. 

Getting informed - the system of alerts allows system administrators to react when the incidence of problems are detected. If the alerts are related to a resource reallocation, it is important to react on time according to the notifications. These alerts are not limited to delivering errors and warnings which are passive means, but rather they can be used as a proactive and defensive measure. 

Estimating future requests (Prediction) - it discovers usage patterns and trends of system resources which allows to projection the increasing of system capacity and performance. 

Reporting - Measured statistics can be viewed in different ways with various visualization tools. Several graphical tools and charts APIs can help identify which resources are consumed the most by whom, what, where, why and when. 

There is a small number of accounting software to provide metered resource utilization in open source cloud platforms. Those tools such as Gold accounting Manager are very simple and are supposed to support system administrators not cloud users. Eucalyptus 2.0 and 3.0 Enterprise generates resource usage information via log messages with user information. We have an idea for a log parsing tool to collect metering values and a command line tool to show metered data. At a certain point, a graphical representation of measured data is required to represent multiple numbers of numerical metrics and we have chosen Google Chart API to generate PNG chart files via command line tools. 

\subsection{Definition}

Once we started investigation on Cloud Accounting tools, similarity of accounting, billing, and monitoring tools is something that we need to clarify. In this section, we give our own words to identify differences among them. 

Monitoring - is about measuring resource utilization. In a typical way, real-time monitoring is performed in a system/hardware layer to show activities. It is supposed to provide performance analysis by measuring CPU utilization, load average, memory usage (free/used), network bandwidth in/out and disk I/O. Given that metrics, monitoring system shows that how many resources are being used at any given time. 

Accounting - is about measuring resource allocation. Unlike monitoring, accounting system doesn't care how much idle exists for allocated resources but rather focuses on collecting and storing usage information in a user level. The size of allocation and the amount of time for the allocation are most important factors to measure resource usage. 

Billing - is about issuing a bill to a user for what they used. Billing system usually sees transactions on an accounting system to include the duration of the used time, type of the used items, and the quantity of the rented resources. It is more like paying a utility bill for a user. 

Auditing - It is about finding a proof and a trait of an action a user made while resources are being used. Observing a user's every behavior should be performed by logging events and detailed information is necessary to track back any issues on a system. 

\section{Usage Measurement on IaaS}

\subsection{OpenStack}

In late 2012, OpenStack community started a new project about measuring usage data from openstack components. This project named Ceilometer collects measurements within OpenStack to achieve monitoring and metering purposes. Ceilometer acquires all of the measurements across all current OpenStack components such as Nova (compute), Network, and Storage (swift), etc and provides a unique framework for the collected data. The latest release Havana includes Ceilometer as a mandatory component in OpenStack and the previous release Grizzly included it as an incubator component.

OpenStack Compute (Nova) also provides a command line tools to retrieve usage statistics, for example, 'nova usage-list' provides usage data for all tenants. These management commands typically limited to system administrators to execute.

\subsubsection{Ceilometer}

Ceilometer project is a framework for monitoring and metering the OpenStack cloud and Ceilometer is a primary place to get access of all usage data in openstack components. It was mainly developed to charge customers as a billing system. Like other commercial cloud platforms, for example Amazon Web Services, these metrics are included, with an hour level granularity :

* Compute (Nova)

* instance type, availability zone

* cpu core

* memory size

* nova volume block device type and availability zone

* Network

* data transfer (in / out), availability zone

* external floating ip

* Storage (Swift)

* disk size used

* data in/out

\subsubsection{Implementation}

There is a program named an agent on each OpenStack node and aggregates information about virtualized resources. The agent on each nova compute node uses Linux virtualization API (libvirt) and Windows Management Instrumentation (wmi) to extract essential information from hypervisor. Some other agents harvest the data from iptables, swift proxy or the nova database, if additional information can be obtained through these external services.

There are four basic components to Ceilometer:

* Agent: runs on each compute node and polls for resources utilization statistics.

* Collector: runs on management servers to manage the message queues for data coming from the agent. Metering data are stored to the openstack data store directly and a notification message are delivered to the Openstack messaging bus once it is processed.

* Data store: is a place of collected data. It provides interaction with the collector and a api server.

* API server: runs on management servers to provide statistics about the measured data.

Figure 1. Architecture of openStack Ceilometer [architectureofopenstackceilometer]

An API server provides access to metering data in the database via a REST API. A central agent polls utilization statistics for other resources not tied to instances or compute nodes. There may be only one instance of the central agent running for the infrastructure. A compute agent polls metering data and instances statistics from the compute node (primarily the hypervisor). Compute agents must run on each compute node that needs to be monitored. A collector monitors the message queues (for notifications sent by the infrastructure and for metering data coming from the agents). Notification messages are processed, turned into metering messages, signed, and sent back out onto the message bus using the appropriate topic. The collector may run on one or more management servers. A data store is a database capable of handling concurrent writes (from one or more collector instances) and reads (from the API server). The collector, central agent, and API may run on any node. These services communicate using the standard OpenStack messaging bus. Only the collector and API server have access to the data store. The supported databases are MongoDB, MySQL, PostgreSQL, HBase and DB2 [ceilometerdatabase]; however, A dedicated host for storing the Ceilometer database is recommended, as it can generate lots of writes . Production scale metering is estimated to have 386 writes per second and 33,360,480 events a day, which would require 239 Gb of volume for storing statistics per month. [volumeofceilometer]

Openstack itself has notification systems built into the existing OpenStack components. Most usage data are collected from these notification systems. Ceilometer also requests metering messages from a pollster plugin using the 'ceilometer.poll.compute' namespace.

\subsubsection{Ceilometer with OpenStack Heat for autoscaling}

The OpenStack Orchestration program, Heat, provides an autoscaling service with Ceilometer like Amazon CloudFormation. OpenStack Heat scales VM capacity up or down according to the metrics from Ceilometer. Ceilometer collects metrics for virtual machines and its alarming module calls the Heat API if the threshold for the metrics is reached. Heat triggers the upscaling or the downscaling virtual machines once it is notified by Ceilometer. This integration of Heat and Ceilometer allows you to ensure optimal utilization by managing the number of virtual machine instances. Amazon has a similar combination of AWS Auto Scaling and AWS CloudWatch to provide the autoscaling service based on monitoring values. [autoscalingwithheatandceilometer]

\subsubsection{Ceilometer on Horizon}

Horizon dashboard, a web-based graphical user interface, adds a new panel for Ceilometer in OpenStack Havana through the admin panel. Figure 2 to 4 show how they are displayed on the web.

Figure 2. Screenshot of ceilometer for disk usage

Figure 3. Screenshot of ceilometer for network usage

Figure 4. Screenshot of ceilometer for visualization

[ceilometeronhorizon]

\subsubsection{Nova command line tools for usage statistics}

Openstack provides usage statistics for OpenStack Compute (Nova), a main component for provisioning and managing virtual machines, with command-line tools. Simple commands displays basic statistics on resource usage for hosts (physica nodes) and instances (virtual objects running on the host). Basic information such as CPU, memory, and disk usage are viewed. These information about allocated resources to the instances do not indicate resource usage on the physical host. For more detailed information about resource usage, Ceilometer has rich functions to see user related or system related usage data. Ceilometer is available on OpenStack Hanava and Grizzly version.

\newline

Example 1. Display a summary of resource usage of the devstack-grizzly host

\begin{lstlisting}

$ nova host-describe sierra
+--------+------------+-----+-----------+---------+
|  HOST  | PROJECT    | cpu | memory_mb | disk_gb |
+--------+------------+-----+-----------+---------+
| sierra | (total)    | 8   | 32176     | 144     |
| sierra | (used_max) | 6   | 12288     | 120     |
| sierra | (used_now) | 6   | 12800     | 120     |
| sierra | project1   | 3   | 6144      | 60      |
| sierra | project2   | 2   | 4096      | 40      |
| sierra | project3   | 1   | 2048      | 20      |
+--------+------------+-----+-----------+---------+

\end{lstlisting}

Usage data can be provided by Tenant Id which is a group of openstack cloud users. Each tenant id represents a group or an account to the group members, so usage data for the tenant id are aggregated.

\newline

Example 2. Summary statistics for tenants

\begin{lstlisting}

$ nova usage-list
Usage from 2014-02-14 to 2014-03-15:
+-----------+-----------+--------------+-----------+---------------+
| Tenant ID | Instances | RAM MB-Hours | CPU Hours | Disk GB-Hours |
+-----------+-----------+--------------+-----------+---------------+
| user1     | 17        | 6840394.43   | 3340.04   | 66800.73      |
| user2     | 17        | 185683.06    | 90.67     | 1813.31       |
| user3     | 1         | 932256.36    | 455.20    | 9104.07       |
| user4     | 26        | 4947215.08   | 2415.63   | 48312.65      |
| user5     | 5         | 18644854.23  | 9103.93   | 182078.65     |
+-----------+-----------+--------------+-----------+---------------+

\end{lstlisting}

[usagestatistics]

Usage data for Ceilometer and the nova command line tools is provided by OpenStack Notification System. The notification system can be configured to emit events either through nova's logging facility, or send them to a series of AMQP queues (one per notification priority). System usages are emitted as notification events with the INFO priority. Different types of usage events are distinguished via the notifications' 'event\_type, which is a hierarchical dotted string such as compute.instance.create, which allows usages to be easily grouped for aggregation. Usage notifications can be immediate, created when a specific increment of usage occurs (such as creation of an instance) or periodic, generated by a periodic task, like a cron job, and covering usage for a certain period of time. Besides the standard Nova Notification priority, notification timestamp, and event\_type, usage notifications contain a payload of data that will vary depending on the event\_type. This is presented as a json-formatted hash of key-value pairs. Some of the keys, such as tenant\_id will always be present in any usage notification, others will be data relevent to that event\_type (For example, instance related notifications will contain data describing the instance.)

[systemusagedata]

\subsection{Eucalyptus}

The Eucalyptus Amazon compatible private cloud has provided resource usage information through external monitoring tools such as Nagios and Ganglia. Since both Nagios and Ganglia have been proved to observe state data within distributed systems, Eucalyptus relied on integration with these tools for resource monitoring. To enhance system management, Eucalyptus recently improves summary reports about resource allocation and status. There are commands line tools for generating reports for eucalyptus cloud that start with eureport- in the Cloud Controller (CLC) and eucadw- in the data warehouse. The reports provide usage data for understanding how cloud resources are utilized and being used via simple command line tools. eureport-generate-report is a main command to get access usage data. Various type of resources can be measured such as elastic-ip, instance, s3, snapshot, and volume when eureport-generate-report is ran with a report type option. The Eucalyptus data warehouse is a place to keep all usage data coming from CLC. External programs can get access to the usage data from the data warehouse instead of CLC directly. It may reduce impact of pulling usage information from cloud when it performs its cloud duties.

[managing-reporting] [eureport-] [eureport-generate-report]

Regarding to commercial clouds, usage data is provided to cloud services running under your account.

\subsection{Azure}

Windows Azure has enhanced their Azure Management Portal, a web-based graphical user interface, with monitoring panels.

- customize monitoring displays,

- verbose monitoring data, (usage data is stored in a storage account which you can access outside of the portal.)

- plot in metrics charts on the monitor page and the dashboard.

Performance Counters provides information about status of operating system, application, service or driver. Counter data can be used to determine resource consumption. Performance Counters is mainly used for monitoring which is gathered from the host operating system for the roles instances (vms). CPU usage(CPU percentage), Network traffic (data in/out), and disk usage (Read throughput, write throughput) are typically collected for minimal monitoring. This is also called performance data.

[howtomonitorcloudservicesazure]

The following diagram illustrates how consumers, the registry, PDH, and performance DLLs and application providers work together.

Figure 5. Overview of Performance Counters

Consumer A uses the registry interface to obtain counter information. Consumer B and the Performance Monitor use PDH to obtain counter information. In turn, the PDH functions can use either the registry interface or WMI.

[AboutPerformanceCounters]

\subsection{Amazon}

\subsubsection{Amazon CloudWatch}

Amazon CloudWatch monitors your Amazon Web Services (AWS) resources and the applications you run on AWS in real-time. ACW is a metrics repository. AWS product puts metrics into the repository, and users retrieve statistics based on those metrics. Metric is a variable you want to measure for your resources and applications. Namespaces are containers for metrics. Metrics are time-ordered sets of data points, are isolated from one another in different namespaces so that metrics from different applications are not mistakenly aggregated into the same statistics. Users retrieve statistics about those data points as an ordered set of time-series data. Over the time value is important for metrics since it contains historical changes in it. Timestamp always follows with a metric. Amazon provides PutMetricData API to create a custom metrics and publish to ACW. 2 weeks time period for store statistics. Each metrics has a dimension, which is a name / value pair that helps you to uniquely identify a metric.

CloudWatch has a notification to alert users and auto scaling (automatically make changes) to the resources you are monitoring based on rules that you define. Simply, CloudWatch manages threshold values to send a notification to users via email or text messages, and even more, apply changes with a pre-defined settings such as increasing virtual instances or diminishing. You gain system-wide visibility into resource utilization, application performance, and operational health.

\subsubsection{Amazon DevPay}

Amazon DevPay is a reseller model which provide a billing and account management service on top of Amazon Web Services (AWS). Amazon DevPay users can measure usage of AWS services, send a bill and collect payments from customers under their subscriptions. DevPay helps a process of billing and tracking for AWS services like Compute (EC2) and Storage (S3).

[AmazonDevPay][resellaws]

Figure 6. Billing Service - Amazon DevPay

\subsection{Monitoring in HPC}

Monitoring in high-performance computing has a similarity to Cloud Computing. It provides fixed number of jobs that a user can create and each job runs on a same size of nodes in clusters. There are also common management tools to clusters, so accounting data can be collected from these tools.

\subsubsection{XDMoD}

XDMoD (XSEDE Metrics on Demand) is primarily developed as UBMoD (University Buffalo Metrics on Demand) and is an open source tools for collecting and mining statistical data from cluster resource managers such as Torque/Maui, OpenPBS, SGE and Slurm commonly found in high-performance computing environments. There are three fundamental components: a metrics repository (XDMoD Data Warehouse), a RESTful API, and a web-based application (XDMoD Portal). Its web graphical user interface, XDMoD Portal, provides rich set of statistics with different type of charts and tables with communicating its RESTful API.

[Performance metrics and auditing framework using application kernels for high-performance computer systems]

[Using XDMoD to Facilitate XSEDE Operations, Planning and Analysis]

\section{Related Work} \label{S:related}
 
\section{System Design} \label{S:design}

\section{Implementation} \label{S:implementation}

TBD
\section{Results and Analyses} \label{S:result}

TBD
 
 
\section{Summary}

TBD 

\appendix{FROM OLD PAPER}

\section{tables}

use
\begin{verbatim}
p{2cm} 
\end{verbatim}
to replace some of the l's in the table, read up what p does, its
width of column


\begin{table*}[htb]
\caption{table 1}\label{T:tab1}
\begin{tabular}{lllll}
Service & Cost Estimate & Pricing (Small/Medium/Large) & Restriction \\
AWS & \$2 & 668.74  & \$0.06 \$0.12 \$0.24 per hour (US East Region; Linux) & Hour basis charge\\
GCE & \$2 & 231.54  & \$0.054 \$0.104 \$0.207 per hour (US Region; Linux) & Minute basis charge with 10-minute minimum\\
Azure & \$2 & 580.03  & \$0.06 \$0.12 \$0.24 per hour (Linux) & Minute basis charge with 5 less minute free\\
\end{tabular}
\end{table*}

\begin{table*}[htb]
\caption{table 2}\label{T:tab2}
\begin{tabular}{llllll}
Instance types & Instance count & Hour basis & Minute basis & With Google 10-minute minimum charge & with Azure 5-minute free \\
small & 165 & 619 hrs (37,140 mins) & 29,622 mins & 29,875 mins &29,582 mins \\
medium & 6 & 268 hrs (16,080 mins) & 15,891 mins & 15,891 mins & 15,891 mins\\
large & 490 & 10,831 hrs (649,860 mins) & 629,969 mins & 631,047 mins & 629,667 mins\\
Total & 661 & 11,718 hrs (703,080 mins) & 675,482 mins & 676,813 mins & 675,140 mins\\
\end{tabular}
\end{table*}


\begin{sidewaystable*}
\caption{table 2}\label{T:tab2}

\begin{small}
\begin{tabular}{|p{2cm}|p{2cm}|p{1.5cm}|p{1.5cm}|p{2cm}|p{1cm}|p{1.5cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
Provider & Charging & Cost 1vCPU/hour	   & Cost 1GB/hour & OS & Max vCPU & Memory min - max &\# of instance types & Discount program & Free allowance\\
\hline
\hline
Aws & hourly & \$0.04  & \$0.02  & Linux & 32 & 615MB - & 22 & spot instance;  & \$100 for educators and student\\
    &  	     &         &  	 & Windows +14-56\%   	&    & 244GB    &       & reserved instances & Grant for researcher, AWS educated grant program\\
    &  	     &         &  	 & Asia + 25\% 		&    & 		       &       &  	  	    & \\
\hline
Google Compute Engine & 10 minutes + & \$0.08  & \$0.01  & Linux (Debian; CentOS) & 16 & 600MB - & 1- & n/a & Google app reward programs\\
 & every minute after that &  &  & (RHEL; SUSE premium operating systems) *** &  & 104GB & (4 high cpu + 4 high memory + 2 small + 5 standard) &  & \$1000 for educator\\
 &  &  & Europe + 4.5\% - 27\%  &  &  &  &  &  & \$60;000 for research project\\
\hline 
IBM CloudLayer (by Softlayer) & monthly & \$0.50  & varies & Linux;  & 16 & 1GB  & Build your own cloud server offers customized options &  & one month trial for 1 vcpu + 1gb memory + 25 storage\\
\hline
 & hourly & to &  & Windows + \$0.05 to &  & -  &  &  & \\
 &  & \$0.10  &  &               \$0.10 / hour &  & 64GB &  &  & \\
\hline 
HP cloud & hourly & \$0.02  & \$0.02  & Linux; Windows; SUSE & 16 & 1GB  & 11 (8 standard + 3 memory intensive) &  & \$300 free trial for 90 days (\$100 for each month)\\
 &  &  &  & (windows: 10-200\% extra charge; &  & -  &  &  & \\
 &  &  &  & SUSE: 4\% - 200\% extra charge) &  & 120GB &  &  & \\
\hline 
Microsoft Azure & Free first 5 minutes & \$0.05  & \$0.02 (approx.) & Linux;  & 8 & 768MB -  & 8 (A0-A7) & 6-Month; 12-month pre-pay membership & \$200 free trial of first month\\
 &  &  & Windows is expensive 30-50\% more than linux & Windows + 30-50\%  &  & 56GB &  &  & \\
\hline 
Rackspace & minute &  & varies & Linux; Windows, (windows: 25\% extra charge) & 32 & 1GB - 120GB  & 9 & Volume discount (4\% to 20\% for spending over \$5;000 - \$ 10; 000 per month; 8\% for \$10;001 - 30;000; 12\% for \$30;001 - \$50;000) Commitment discount (4\% to 40\%) Prepayment discount with commitment (7\% to 55\%)& \$300 developer discount (\$50 each for six months)\\
\hline
\end{tabular}
\end{small}
\end{sidewaystable*}


\section{Images}



\begin{figure}[htb] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig1.pdf} 
  \caption{The Architecture of the Framework}\label{F:fig1} 
\end{figure} 

\begin{figure}[htb] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig2.pdf} 
  \caption{The Architecture of the Framework}\label{F:fig2} 
\end{figure} 

\begin{figure}[htb] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig3.pdf} 
  \caption{The Architecture of the Framework}\label{F:fig3} 
\end{figure} 

\begin{figure}[htb] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig4.pdf} 
  \caption{The Architecture of the Framework}\label{F:fig4} 
\end{figure} 

\begin{figure}[htb] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig5.pdf} 
  \caption{The Architecture of the Framework}\label{F:fig5} 
\end{figure} 

\begin{figure}[htb] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig6.pdf} 
  \caption{The Architecture of the Framework}\label{F:fig6} 
\end{figure} 

\begin{figure}[htb] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig3b.pdf} 
  \caption{The Architecture of the Framework}\label{F:fig7} 
\end{figure} 

\begin{figure}[htb] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig4b.pdf} 
  \caption{The Architecture of the Framework}\label{F:fig8} 
\end{figure} 


\section{USE CASE EXAMPLES}

\section{FutureGrid}

Based on the observation on FutureGrid, there is a different pattern between a research project and class work when they acquire cloud resources.  Resource allocation of academic coursework shows time dependent request patterns. It shows a surge when there is a class, a lab session, and a project. For example, the undergraduate course for Distributed Systems at Indiana University introduced IaaS in the class and used the IaaS platform for a class project. Figure 1 shows a spike in the class and variability until the project due. Research projects request VM instances in a bit more steady usage compared to the coursework. The Next Generation Sequencing (NGS) in the cloud project on FutureGrid shows relatively consistent resource allocation requested in Figure 2. With a certain period of time, vm instances of this project have been launched without unplanned spike requests. These examples show different patterns for requesting resources but both cases have a factor to predict loads. The class schedule and the monitoring and profiling data for applications can be used to measure the amount of resources and identify incoming requests. In paid cloud platforms such as AWS, GCE, and Azure, understanding these patterns for provisioning is important to bring cost effectiveness over on-demand allocation. For example, Amazon EC2 Reserved Instances and Azure pre-pay plans may help reduce usage costs for periodic and planned workloads. These service plans simply provide discounts with an upfront payment. As long as a class and a project go as planned, cost saving chances are increased. 

Figure 1. IaaS Usage data for the Distributed System class at Indiana University*

% * Based on the class schedule and metrics. Class schedule is here: http://salsahpc.indiana.edu/csci-p434-fall-2013/
% Metrics is here: http://129.79.49.94/accounting/reports/custom/p434fall13/FGResourceReport.pdf

 
Figure 2. VM count for Next Generation Sequencing (NGS) in the cloud project

With the Gantt chart in Figure 3, allocation activities are viewed for all virtual instances launched for the class. At the beginning of the class, the gaps between the start and completed dates of the vm instances are small but a large number of instances are initiated. Once the class is became operative,  running time for vm instances is getting longer and a smaller number of instances are requested compared to the beginning. This observation tells that academic projects require training sessions at the beginning of the project to get familiar with using infrastructure and to prepare environments by installing software and datasets.

 
Figure 3. Timeline for VM walltime

Other observation is that resource usage for administrative purposes. Figure 4 describes that instructors consumed a large number of vCPU cores before class starts and small tests just before class projects. It indicates that the preparation of courses require extensive load testing on cloud resources to estimate compute capacity needed for applications.

 
Figure 4. Usage between instructors and students for vCPU cores

During the semester, 25 hosts, 216 vCPUs and 600GB memories were reserved for the class since it required large virtual instances. In Figure 5 shows that the dedicated resources were being underutilized most time although the high volume requests had been made a few times including 273% overutilization on October 21th for testing and preparing.
 
Figure 5. vCPU Utilization (approximation per hour)

\section{COMPARISON}

% Provider	Charging	Cost
% 1 vCPU /hour	Cost
% 1 GB
% /hour	OS	Max vCPU	Memory min - max	\# of instance types	Discount program	Free allowance
% Aws
% 	hourly	\$0.04
% 	$0.01927	Linux
% Windows +14-56% 
% Asia + 25%	32	615MB -
% 244GB	22	spot instance, 
% reserved instances	$100 for educator's student
% Grant for researcher
% AWS educated grant program
% Google Compute Engine	10 minutes +
% every minute after that	$0.0788
% 	$0.006636
% 
% Europe + 4.5% - 27% 	Linux (Debian, CentOS)
% (RHEL, SUSE premium operating systems) ***	16	600MB -
% 104GB	15
% (4 high cpu + 4 high memory + 2 small + 5 standard)	n/a	Google app reward programs
% $1000 for educator
% $60,000 for research project
% IBM CloudLayer (by Softlayer)	monthly
% hourly	$0.5
% to
% $0.10	varies	Linux, 
% Windows + $0.05 to
%               $0.10 / hour	16	1GB 
% – 
% 64GB	Build your own cloud server offers customized options		one month trial for 1 vcpu + 1gb memory + 25 storage
% HP cloud	hourly	$0.015	$0.015	Linux, Windows, SUSE
% (windows: 10-200% extra charge,
% SUSE: 4% - 200% extra charge)	16	1GB 
% – 
% 120GB	11 (8 standard + 3 memory intensive)		$300 free trial for 90 days ($100 for each month)
% Microsoft Azure	Free first 5 minutes
% 	$ 0.05	$0.02 (approx.)
% Windows is expensive 30-50% more than linux	Linux, 
% Windows + 30-50% 	8	768MB – 
% 56GB	8 (A0-A7)	6-Month, 12-month pre-pay membership	$200 free trial of first month
% Rackspace	minute		varies	Linux, Windows
% (windows: 25% extra charge)	32	1GB – 
% 120GB	9	Volume discount (4% to 20% for spending over $5,000 - $ 10, 000 per month, 8% for $10,001 - 30,000, 12% for $30,001 - $50,000)
% Commitment discount (4% to 40%)
% Prepayment discount with commitment (7% to 55%)	$300 developer discount ($50 each for six months)


\section{FOR PAY ALLOCATIONS}

\subsection{Pricing Comparison in IaaS}

Comparing pricing of the cloud is complicated and may lead to false analogy because each cloud provider offers various services with different performance. The pricing comparison, however, is important when people start to consider adopting cloud services among a lot of selections from different providers. In the comparison, important criteria are revealed through its pricing table. For example, there are a range of service offered, a size of available systems, costs, discounts and benefits such as technical support, and development tools. Amazon AWS, Windows Azure, Google Compute Engine, HP Cloud, IBM and Rackspace are compared.

\subsection{Example of pricing comparison}

We tried to apply each pricing model; Amazon AWS, Google Compute Engine, Microsoft Azure; to the usage data of class (P434 distributed systems at Indiana University), to compare cost estimate of cloud resource. Google Compute Engine is the least expensive and 16\% lower than Amazon AWS. It is mostly because of that Google has 10\% discount pricing chart compared to AWS. We observed that a minute basis charge is only 3.3\% less expensive for this class. Some restrictions and offers such as Google's 10-minute minimum charge and Azure's less 5-minute free of charge are relatively small amount of a discount or an extra charge. Google's 10-minute minimum charge asks 0.18\% extra charge to the class, Azure provides 0.05\% discount through their less 5-minute free of charge. Amazon only has an hourly based pricing model, while Google Compute Engine and Windows Azure offer a minute basis charge for use of virtual machine instances. Three types of instances (small/medium/large) had been used for its coursework and projects and usage of virtual machine instances was only calculated without network and storage usage. Table 3, 4 shows pricing comparison to the class.

Table 3. Usage data of the class

Instance types	Instance count	Hour basis	Minute basis	With Google 10-minute minimum charge	with Azure 5-minute free
small	165	619 hrs (37,140 mins)	29,622 mins	29,875 mins	29,582 mins
medium	6	268 hrs (16,080 mins)	15,891 mins	15,891 mins	15,891 mins
large	490	10,831 hrs (649,860 mins)	629,969 mins	631,047 mins	629,667 mins
Total	661	11,718 hrs (703,080 mins)	675,482 mins	676,813 mins	675,140 mins
* Instance types are not same. Chosen by a similarity of vCPU and Memory
** Captured by January, 2014

Table 4. Pricing comparison to the class
Service	Cost Estimate	Pricing (Small/Medium/Large)	Restriction
AWS	$2,668.74	$0.06\$0.12\$0.24 per hour (US East Region, Linux)	Hour basis charge
GCE	$2,231.54	$0.054\$0.104\$0.207 per hour (US Region, Linux)	Minute basis charge with 10-minute minimum
Azure	$2,580.03	$0.06\$0.12\$0.24 per hour (Linux)	Minute basis charge with 5 less minute free

\subsection{Comparison}

Table 1. Pricing chart for instances from AWS, GCE, and Azure
	Billing granularity	Price	Variation for Price
AWS	By hour	\$0.02 (smallest)*	10 regions**, 6 platforms
GCE	By minute, with a minimum of 10 minutes	\$0.019 (smallest)*	2 regions (Us, Europe)
Azure	By minute, No minimum, No billing for less than 5 minutes	\$0.02 (smallest)*	6 regions, 5 platforms
* Smallest VM instance: 1 virtual core, 600~768MB memory, no storage
** China (Beijing) region will be available in early 2014, and GovCloud region is also included.

Pricing is scenario based. It can't be simply compared with numbers. GCE looks cheaper than other competitors, but others have more options to save a cost. For example, a pay-ahead model provides a discount for same instances, and a spot instance also provides a way of saving entire cost for task intensive workloads in a small amount of time.


\subsection{Tools for Cloud Pricing}

To help understand costs of cloud computing, several tools offer various functions to calculate estimate and analyze cloud spending and usage data. With these tools, researchers and educators can make a plan for cloud deployments and prepare spending across several cloud providers. Each cloud service consists of complicated architectures and different performance levels and so users need to understand that these tools for cloud pricing are designed to minimize costs and provide guidelines in terms of finding the most effective cloud services.

1. PlanForCloud Calculator
PlanForCloud Calculator is a free cloud cost forecasting website that
helps evaluate costs for a project or an operation from a variety of
cloud providers. With PlanForCloud, Amazon Web services (AWS), Google
Compute Engine (GCE), Microsoft Windows Azure, Rackspace, IBM
Softlayer, and HP Cloud are compared for servers, storage, databases,
data transfer, and other services to estimate resource usage in the
future. This calculator also provides a simulation on planned
deployments and 3-year cost reports. Estimated expenditures can be
illustrated to reduce uncertainty for the future consumption of cloud
resources. 

% [http://www.rightscale.com/news_events/press_releases/2012/rightscale-introduces-cloud-cost-forecasting-with-launch-of-planforcloud.php]

[Helen Heinrich (2013) Tech Servises on the Web: The PlanforCloud
Calculator http://www.planforcloud.com/ , Technical Services Quarterly, 30:1, 120-121, DOI:
10.1080/07317131.2013.735980]

 
Figure 3. Example of a cloud usage report by PlanForCloud from RightCcale **

** screenshot from http://www.rightscale.com/images/pfc-report-page.jpg


 
Figure 4. Example of Cloud Analytics from Rightscale***

***screenshot from http://www.rightscale.com/images/screenshots/cloud-cost-forecasting.png

*	http://www.profitbricks.com/compare-cloud-pricing/
%*	https://cloudvertical.com/cloud-costs#cloud_costs/index
*	http://mikekhristo.com/ec2-ondemand-vs-reserved-instance-savings-calculator/
*	http://blog.cloudphysics.com/blog/2013/11/18/do-hybrid-clouds-make-cents-free-cost-calculator-for-aws
*	http://geekswithblogs.net/hroggero/archive/2013/02/18/sample-pricing-comparison-amazon-aws-and-windows-azure.aspx
*	http://www.stratalux.com/2013/05/08/strataluxs-aws-pricing-tool/
*	http://www.webrmedia.com/blog/apps/calculate-your-amazon-aws-hosting-costs-using-excel

\section{Citations}

just to show whats in cyberaide-metrics.bib

% \cite{www-c,www-b,www-a,www-abc,www-salsa-class,www-amzon-calculator2,www-o,www-n,www-m,www-l,www-k,www-j,www-i,www-h,www-g,www-f,www-w,www-v,www-u,www-t,www-s,www-r,www-q,www-p,www-e,www-d,www-amzon-calculator-1,www-amzon-calculator-2}
 

 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Acknowledgment 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
  
\section*{Acknowledgement} 
 
This material is based upon work supported in part by the National Science Foundation under Grant No. 0910812.

 
%\clearpage 
 
\bibliographystyle{IEEEtranS} 
%\bibliographystyle{abbrv} 
\bibliography{% 
bib/vonLaszewski-jabref,% 
bib/cyberaide-metric,%
bib/cyberaide-cloud}
%bib/image-refs,% 

%bib/python,% 
%tas.bib%
 
\end{document} 
 
 
