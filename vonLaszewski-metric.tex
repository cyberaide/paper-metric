\documentclass{sig-alternate} 

\newcommand{\TITLE}{Towards Understanding Cloud Usage through Resource Allocation Analysis}
\newcommand{\AUTHOR}{Hyungro Lee, Gregor von Laszewski, Fugang Wang} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% LATEX DEFINITIONS 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{hyperref} 
\usepackage{array} 
\usepackage{graphicx} 
\usepackage{booktabs} 
\usepackage{pifont} 
\usepackage{todonotes} 
\usepackage{rotating} 
\usepackage{color} 
\usepackage{listings}

\newcommand*\rot{\rotatebox{90}} 
 
\newcommand{\FILE}[1]{\todo[color=green!40]{#1}} 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% HYPERSETUP 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hypersetup{ 
    bookmarks=true,         % show bookmarks bar 
    unicode=false,          % non-Latin characters in Acrobat’s bookmarks 
    pdftoolbar=true,        % show Acrobat’s toolbar 
    pdfmenubar=true,        % show Acrobat’s menu 
    pdffitwindow=false,     % window fit to page when opened 
    pdfstartview={FitH},    % fits the width of the page to the window 
    pdftitle={\TITLE},    % title 
    pdfauthor={\AUTHOR},     % author 
    pdfsubject={Subject},   % subject of the document 
    pdfcreator={Gregor von Laszewski, Fugang Wang},   % creator of the document 
    pdfproducer={Gregor von Laszewski}, % producer of the document 
    pdfkeywords={hindex} {metric}{XSEDE} {FutureGrid}, % list of keywords 
    pdfnewwindow=true,      % links in new window 
    colorlinks=false,       % false: boxed links; true: colored links 
    linkcolor=red,          % color of internal links (change box color with linkbordercolor) 
    citecolor=green,        % color of links to bibliography 
    filecolor=magenta,      % color of file links 
    urlcolor=cyan           % color of external links 
} 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\lstset{frame=tb,
language=sh,
aboveskip=3mm,
belowskip=3mm,
showstringspaces=false,
columns=flexible,
basicstyle={\scriptsize\ttfamily},
numbers=none,
numberstyle=\tiny\color{gray},
keywordstyle=\color{blue},
commentstyle=\color{dkgreen},
stringstyle=\color{mauve},
breaklines=true,
breakatwhitespace=true
tabsize=3
}
\begin{document} 
% 
% --- Author Metadata here --- 
\conferenceinfo{TBD}{TBD Address} 
\CopyrightYear{2014}  
\crdata{X-XXXXX-XX-X/XX/XX}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE. 
% --- End of Author Metadata --- 
 
\title{\TITLE} 
%\subtitle{[Extended Abstract] 
%\titlenote{A full version of this paper is available as 
%\texttt{www.acm.org/eaddress.htm}}} 
 
\numberofauthors{4}  
\author{ 
\alignauthor 
Hyungro Lee\\ 
       \affaddr{Indiana University}\\ 
       \affaddr{2719 10th Street}\\ 
       \affaddr{Bloomington, Indiana, U.S.A.}\\ 
\alignauthor 
Gregor von Laszewski\titlenote{Corresponding Author.}\\ 
       \affaddr{Indiana University}\\ 
       \affaddr{2719 10th Street}\\ 
       \affaddr{Bloomington, Indiana, U.S.A.}\\ 
       \email{laszewski@gmail.com} 
\alignauthor 
Fugang Wang\\ 
       \affaddr{Indiana University}\\ 
       \affaddr{2719 10th Street}\\ 
       \affaddr{Bloomington, Indiana, U.S.A.}\\ 
% 3rd. author 
\and
\alignauthor 
Geoffrey C. Fox\\ 
       \affaddr{Indiana University}\\ 
       \affaddr{2719 10th Street}\\ 
       \affaddr{Bloomington, Indiana, U.S.A.}\\ 
\and  % use '\and' if you need 'another row' of author names 
} 
\date{13 March 2014} 
 
\toappear{} 
\maketitle 
\begin{abstract} 

In utility computing, usage data is necessary to identify utilization of the infrastructure by users. Many cloud platforms recently started to collect measurements for use of resources that can be applied to billing and monitoring. The usage data allows a user to see as how all resources are efficiently supplied to their applications and discover usage pattern in historical data. Virtual resources such as compute, storage and network are typically measured to evaluate time and cost of user applications and the statistics for resource used offer visibility to utilization of the cloud. With FutureGrid CloudMetrics, cloud usage data can be collected in an integrated accounting framework across OpenStack, Eucalyptus, and Nimbus IaaS platforms. This article provides statistical analysis of FutureGrid projects by tracing resource allocation on FutureGrid resources.

\end{abstract} 
 
% A category with the (minimum) three required fields 
\category{H.4}{Information Systems Applications}{Miscellaneous} 
%A category including the fourth, optional field follows... 
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures] 
 
\terms{Theory} 
 
\keywords{Scientific impact, bibliometric, h-index, Technology audit, XSEDE} 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% SECTIONS 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 
\section{Introduction} 

\subsection{Background}
In distributed systems and HPC, resource usage are typically monitored to detect any hardware and software issues. Real-time monitoring applications help provide sustain and consistent services and engage performance of their system. Distributed systems were built with complex hardwares and require to incorporate with various hardwares such as router, switch, network, and servers along with computing resources like cpu, memory and disk. In Cloud Computing, people have attention to monitoring and accounting systems in virtualized environments, so that they can measure resource consumption which is what they are paying for on the on-demand service, cloud computing. 

Many places now adopt virtualization and cloud services to enhance the capacity of their system infrastructure and performance. Performance management is getting more important in this regard for identifying and delivering reasonable resource allocation. But traditional performance software are still designed to measure a certain type of resources and system administrators raised needs for a unified performance management with virtual resource allocation which provides a bird eye's view to monitor system utilization with the proper provision and allocation of resources [1]. The unified monitoring software is not only about an integrating metric units and aggregating numerical values but also about making sure that the applications on the services are efficiently consuming allocated resources and the resources are properly allocated in the right place at the right time. Understanding system utilization and application performance with the observation from the software is important to satisfy service-level agreements (SLAs) and improve the system administration, however in a virtualized environment, measuring shared resources is not an easy task since they are in multiple points and different layers. 

\subsection{Real Consumption vs Allocation}
There are two types of measuring resource usage on the cloud. Like a conventional monitoring, resource consumption on the cloud is based on current usage data for cpu, memory, network and disk traffics. These are dynamically changing according to traffics, and are important to validate system health frequently. The other type of measuring resource usage is measuring the amount of allocated resources. It is an accounting system that records allocation of resources. In a shared resource environment which is a fundamental concept in utility computing, the amount of allocated resource means that your requested resource will be dominated to you not interrupted by any other users. Resource allocation is not measuring real-time resource usage. Instead, it records rented resources in an accounting book for billing and charging. There are static metrics for allocation such as allocated number of cpu cores, memories, and disks. Number of public IP addresses is also counted for metrics.

\subsection{Motivation}

Investigation for performance managements on the cloud would provide understanding of resource usage and statistics in several ways such as accounting/billing and provisioning. This classification will help evaluate the current performance of the cloud systems and gain the visibility of resource utilization across application layer and system layer. 

\subsection{Problem}

Cloud platform relies on sharing of computing and storage resources with many people like a public utility, understanding amounts of the usage of resources is getting important to the cloud users and cloud providers. It is not only important measuring use of resources but also important displaying metrics via graphical charts. There are concrete challenges for this research area: 

Understanding - it is a basic functionality to see how reliable the system is and to prevent system failures by knowing the resource utilization. It also gives an opportunity to manage the system efficiently by knowing the performance of the system. 

Getting informed - the system of alerts allows system administrators to react when the incidence of problems are detected. If the alerts are related to a resource reallocation, it is important to react on time according to the notifications. These alerts are not limited to delivering errors and warnings which are passive means, but rather they can be used as a proactive and defensive measure. 

Estimating future requests (Prediction) - it discovers usage patterns and trends of system resources which allows to projection the increasing of system capacity and performance. 

Reporting - Measured statistics can be viewed in different ways with various visualization tools. Several graphical tools and charts APIs can help identify which resources are consumed the most by whom, what, where, why and when. 

There is a small number of accounting software to provide metered resource utilization in open source cloud platforms. Those tools such as Gold accounting Manager are very simple and are supposed to support system administrators not cloud users. Eucalyptus 2.0 and 3.0 Enterprise generates resource usage information via log messages with user information. We have an idea for a log parsing tool to collect metering values and a command line tool to show metered data. At a certain point, a graphical representation of measured data is required to represent multiple numbers of numerical metrics and we have chosen Google Chart API to generate PNG chart files via command line tools. 

\subsection{Definition}

Once we started investigation on Cloud Accounting tools, similarity of accounting, billing, and monitoring tools is something that we need to clarify. In this section, we give our own words to identify differences among them. 

\subsubsection{Monitoring}

Monitoring is about measuring resource utilization. In a typical way, real-time monitoring is performed in a system/hardware layer to show activities. It is supposed to provide performance analysis by measuring CPU utilization, load average, memory usage (free/used), network bandwidth in/out and disk I/O. Given that metrics, monitoring system shows that how many resources are being used at any given time. 

\subsubsection{Accounting}

Accounting is about measuring resource allocation. Unlike monitoring, accounting system doesn't care how much idle exists for allocated resources but rather focuses on collecting and storing usage information in a user level. The size of allocation and the amount of time for the allocation are most important factors to measure resource usage. 

\subsubsection{Billing}

Billing is about issuing a bill to a user for what they used. Billing system usually sees transactions on an accounting system to include the duration of the used time, type of the used items, and the quantity of the rented resources. It is more like paying a utility bill for a user. 

\subsubsection{Auditing}

Auditing is about finding a proof and a trait of an action a user made while resources are being used. Observing a user's every behavior should be performed by logging events and detailed information is necessary to track back any issues on a system. 

\section{Usage Measurement for IaaS}

\subsection{OpenStack}

In late 2012, OpenStack community started a new project about measuring usage data from openstack components. This project named Ceilometer collects measurements within OpenStack to achieve monitoring and metering purposes. Ceilometer acquires all of the measurements across all current OpenStack components such as Nova (compute), Network, and Storage (swift), etc and provides a unique framework for the collected data. The latest release Havana includes Ceilometer as a mandatory component in OpenStack and the previous release Grizzly included it as an incubator component.

OpenStack Compute (Nova) also provides a command line tools to retrieve usage statistics, for example, 'nova usage-list' provides usage data for all tenants. These management commands typically limited to system administrators to execute.

\subsubsection{Ceilometer}

Ceilometer project is a framework for monitoring and metering the OpenStack cloud and Ceilometer is a primary place to get access of all usage data in openstack components. It was mainly developed to charge customers as a billing system. Like other commercial cloud platforms, for example Amazon Web Services, these metrics are included, with an hour level granularity :

\begin{itemize}
  \item Compute (Nova)
  \item instance type, availability zone
  \item cpu core
  \item memory size
  \item nova volume block device type and availability zone
  \item Network
  \item data transfer (in / out), availability zone
  \item external floating ip
  \item Storage (Swift)
  \item disk size used
  \item data in/out
\end{itemize}

\subsubsection{Implementation}

There is a program named an agent on each OpenStack node and aggregates information about virtualized resources. The agent on each nova compute node uses Linux virtualization API (libvirt) and Windows Management Instrumentation (wmi) to extract essential information from hypervisor. Some other agents harvest the data from iptables, swift proxy or the nova database, if additional information can be obtained through these external services.

There are four basic components to Ceilometer:

\begin{itemize}
  \item Agent: runs on each compute node and polls for resources utilization statistics.
  \item Collector: runs on management servers to manage the message queues for data coming from the agent. Metering data are stored to the openstack data store directly and a notification message are delivered to the Openstack messaging bus once it is processed.
  \item Data store: is a place of collected data. It provides interaction with the collector and a api server.
  \item API server: runs on management servers to provide statistics about the measured data.
\end{itemize}

An API server provides access to metering data in the database via a REST API. A central agent polls utilization statistics for other resources not tied to instances or compute nodes. There may be only one instance of the central agent running for the infrastructure. A compute agent polls metering data and instances statistics from the compute node (primarily the hypervisor). Compute agents must run on each compute node that needs to be monitored. A collector monitors the message queues (for notifications sent by the infrastructure and for metering data coming from the agents). Notification messages are processed, turned into metering messages, signed, and sent back out onto the message bus using the appropriate topic. The collector may run on one or more management servers. A data store is a database capable of handling concurrent writes (from one or more collector instances) and reads (from the API server). The collector, central agent, and API may run on any node. These services communicate using the standard OpenStack messaging bus. Only the collector and API server have access to the data store. The supported databases are MongoDB, MySQL, PostgreSQL, HBase and DB2 [ceilometerdatabase]; however, A dedicated host for storing the Ceilometer database is recommended, as it can generate lots of writes . Production scale metering is estimated to have 386 writes per second and 33,360,480 events a day, which would require 239 Gb of volume for storing statistics per month. [volumeofceilometer]

Openstack itself has notification systems built into the existing OpenStack components. Most usage data are collected from these notification systems. Ceilometer also requests metering messages from a pollster plugin using the 'ceilometer.poll.compute' namespace.

\subsubsection{Ceilometer with OpenStack Heat for autoscaling}

The OpenStack Orchestration program, Heat, provides an autoscaling service with Ceilometer like Amazon CloudFormation. OpenStack Heat scales VM capacity up or down according to the metrics from Ceilometer. Ceilometer collects metrics for virtual machines and its alarming module calls the Heat API if the threshold for the metrics is reached. Heat triggers the upscaling or the downscaling virtual machines once it is notified by Ceilometer. This integration of Heat and Ceilometer allows you to ensure optimal utilization by managing the number of virtual machine instances. Amazon has a similar combination of AWS Auto Scaling and AWS CloudWatch to provide the autoscaling service based on monitoring values. [autoscalingwithheatandceilometer]

\subsubsection{Ceilometer on Horizon}

Horizon dashboard, a web-based graphical user interface, adds a new panel for Ceilometer in OpenStack Havana through the admin panel.

[ceilometeronhorizon]

\subsubsection{Nova command line tools for usage statistics}

Openstack provides usage statistics for OpenStack Compute (Nova), a main component for provisioning and managing virtual machines, with command-line tools. Simple commands displays basic statistics on resource usage for hosts (physica nodes) and instances (virtual objects running on the host). Basic information such as CPU, memory, and disk usage are viewed. These information about allocated resources to the instances do not indicate resource usage on the physical host. For more detailed information about resource usage, Ceilometer has rich functions to see user related or system related usage data. Ceilometer is available on OpenStack Hanava and Grizzly version. \newline
Example 1. Display a summary of resource usage of the devstack-grizzly host

\begin{lstlisting}

$ nova host-describe sierra
+--------+------------+-----+-----------+---------+
|  HOST  | PROJECT    | cpu | memory_mb | disk_gb |
+--------+------------+-----+-----------+---------+
| sierra | (total)    | 8   | 32176     | 144     |
| sierra | (used_max) | 6   | 12288     | 120     |
| sierra | (used_now) | 6   | 12800     | 120     |
| sierra | project1   | 3   | 6144      | 60      |
| sierra | project2   | 2   | 4096      | 40      |
| sierra | project3   | 1   | 2048      | 20      |
+--------+------------+-----+-----------+---------+

\end{lstlisting}

Usage data can be provided by Tenant Id which is a group of openstack cloud users. Each tenant id represents a group or an account to the group members, so usage data for the tenant id are aggregated. \newline

Example 2. Summary statistics for tenants

\begin{lstlisting}

$ nova usage-list
Usage from 2014-02-14 to 2014-03-15:
+-----------+-----------+--------------+-----------+---------------+
| Tenant ID | Instances | RAM MB-Hours | CPU Hours | Disk GB-Hours |
+-----------+-----------+--------------+-----------+---------------+
| user1     | 17        | 6840394.43   | 3340.04   | 66800.73      |
| user2     | 17        | 185683.06    | 90.67     | 1813.31       |
| user3     | 1         | 932256.36    | 455.20    | 9104.07       |
| user4     | 26        | 4947215.08   | 2415.63   | 48312.65      |
| user5     | 5         | 18644854.23  | 9103.93   | 182078.65     |
+-----------+-----------+--------------+-----------+---------------+

\end{lstlisting}

[usagestatistics]

Usage data for Ceilometer and the nova command line tools is provided by OpenStack Notification System. The notification system can be configured to emit events either through nova's logging facility, or send them to a series of AMQP queues (one per notification priority). System usages are emitted as notification events with the INFO priority. Different types of usage events are distinguished via the notifications' 'event\_type, which is a hierarchical dotted string such as compute.instance.create, which allows usages to be easily grouped for aggregation. Usage notifications can be immediate, created when a specific increment of usage occurs (such as creation of an instance) or periodic, generated by a periodic task, like a cron job, and covering usage for a certain period of time. Besides the standard Nova Notification priority, notification timestamp, and event\_type, usage notifications contain a payload of data that will vary depending on the event\_type. This is presented as a json-formatted hash of key-value pairs. Some of the keys, such as tenant\_id will always be present in any usage notification, others will be data relevent to that event\_type (For example, instance related notifications will contain data describing the instance.)

[systemusagedata]

\subsection{Eucalyptus}

The Eucalyptus Amazon compatible private cloud has provided resource usage information through external monitoring tools such as Nagios and Ganglia. Since both Nagios and Ganglia have been proved to observe state data within distributed systems, Eucalyptus relied on integration with these tools for resource monitoring. To enhance system management, Eucalyptus recently improves summary reports about resource allocation and status. There are commands line tools for generating reports for eucalyptus cloud that start with eureport- in the Cloud Controller (CLC) and eucadw- in the data warehouse. The reports provide usage data for understanding how cloud resources are utilized and being used via simple command line tools. eureport-generate-report is a main command to get access usage data. Various type of resources can be measured such as elastic-ip, instance, s3, snapshot, and volume when eureport-generate-report is ran with a report type option. The Eucalyptus data warehouse is a place to keep all usage data coming from CLC. External programs can get access to the usage data from the data warehouse instead of CLC directly. It may reduce impact of pulling usage information from cloud when it performs its cloud duties.

[managing-reporting] [eureport-] [eureport-generate-report]

Regarding to commercial clouds, usage data is provided to cloud services running under your account.

\subsection{Azure}

Microsoft Azure - Microsoft Windows Azure is a cloud computing platform used to build, host and scale web applications through Microsoft data centers [1]. The platform contains various on-demand services hosted in Microsoft data centers. These services are provided through three products.

\begin{itemize}
 \item Windows Azure: an operating system that provides scalable compute and storage facilities.
 \item SQL Azure: a cloud based, scale out version of SQL server.
 \item Windows Azure AppFabric: a collection of services supporting applications both in the cloud and on premise.
\end{itemize}

The System Center Monitoring Pack for Windows Azure application is the most cost effective and flexible platform for managing traditional data centers, private and public clouds, and client computers and devices [2]. It provides monitoring of availability and performance for Windows Azure applications. It is the only unified management platform where multiple hypervisors, physical resources, and applications can be managed in a single offering. From a single console view, the IT assets like network, storage and compute can be organized into a hybrid cloud model spanning the private cloud and public cloud services.

The monitoring pack runs on a specified agent and uses Windows API.s to remotely discover and collect information about a specified Windows Azure application. By default, the monitoring is not enabled. Therefore, the discovery must be configured by using the Windows Azure Application monitoring template for each Windows Azure Application to be monitored.

The following functionalities are provided by the Monitoring Pack for Windows Azure Applications:

\begin{itemize}
 \item Discovers Windows Azure applications.
 \item Provides status of each role instance.
 \item Collects and monitors performance information.
 \item Collects and monitors Windows events.
 \item Collects and monitors the .NET Framework trace messages from each role instance.
 \item Grooms performance, event, and the .NET Framework trace data from Windows Azure storage account.
 \item Changes the number of role instances.
\end{itemize}

Implementing monitoring means, launching the diagnostic instance and this instance will collect the data and at the interval user wants. The collected data will be copied to an Azure Table:

\begin{itemize}
\item WADPerformanceCountersTable for the performance counters
\item WADWindowsEventLogsTable for the windows event logs.
\end{itemize}

The performance monitoring can be enabled by implementing some code or using some tools like:

\begin{itemize}
\item Powershell cmdlets for Windows Azure [3]
\item Azure Diagnostics Manager 2 from Cerebrata [4]
\end{itemize}

By using these tools one instance of Windows Azure is configured to collect some performance counters without modifying the application code. The performance data will be collected by the Azure Diagnostic Monitor and moved at the interval user specified to a table called WADPerformanceCounters. User can use diagnostic data for debugging and troubleshooting, measuring performance, monitoring resource usage, traffic analysis and capacity planning, and auditing. Diagnostic data is not permanently stored unless user transfers the data to the Windows Azure storage emulator or to Windows Azure storage. After the data is transferred to storage it can be viewed with one of several available tools. To collect Windows Event logs in a Windows Azure application, the Event logs data source must be configured.

Once, the Azure Management Pack is installed, three .run as. accounts must be created in System Center Operation Manager:

\begin{itemize}
 \item One for binary authentication. This account will use the management certificate to connect to Azure.
 \item One for basic authentication. This account will be used for the certificate
 \item One that will be used for the proxy agent.
\end{itemize}
 
The monitoring data can be visualized using System Center Operation Manager Console. From Operation Manager, user can create custom dashboard or publish graphs on SharePoint to people who do not have the SCOM console.

\subsection{Amazon}

\subsubsection{Amazon CloudWatch}

Amazon CloudWatch monitors your Amazon Web Services (AWS) resources and the applications you run on AWS in real-time. ACW is a metrics repository. AWS product puts metrics into the repository, and users retrieve statistics based on those metrics. Metric is a variable you want to measure for your resources and applications. Namespaces are containers for metrics. Metrics are time-ordered sets of data points, are isolated from one another in different namespaces so that metrics from different applications are not mistakenly aggregated into the same statistics. Users retrieve statistics about those data points as an ordered set of time-series data. Over the time value is important for metrics since it contains historical changes in it. Timestamp always follows with a metric. Amazon provides PutMetricData API to create a custom metrics and publish to ACW. 2 weeks time period for store statistics. Each metrics has a dimension, which is a name / value pair that helps you to uniquely identify a metric.

CloudWatch has a notification to alert users and auto scaling (automatically make changes) to the resources you are monitoring based on rules that you define. Simply, CloudWatch manages threshold values to send a notification to users via email or text messages, and even more, apply changes with a pre-defined settings such as increasing virtual instances or diminishing. You gain system-wide visibility into resource utilization, application performance, and operational health.

\section{Monitoring on HPC}

Monitoring in high-performance computing has a similarity to Cloud Computing. It provides fixed number of jobs that a user can create and each job runs on a same size of nodes in clusters. There are also common management tools to clusters, so accounting data can be collected from these tools.

\subsection{XDMoD}

XDMoD (XSEDE Metrics on Demand) is primarily developed as UBMoD (University Buffalo Metrics on Demand) and is an open source tools for collecting and mining statistical data from cluster resource managers such as Torque/Maui, OpenPBS, SGE and Slurm commonly found in high-performance computing environments. There are three fundamental components: a metrics repository (XDMoD Data Warehouse), a RESTful API, and a web-based application (XDMoD Portal). Its web graphical user interface, XDMoD Portal, provides rich set of statistics with different type of charts and tables with communicating its RESTful API.

[Performance metrics and auditing framework using application kernels for high-performance computer systems]

[Using XDMoD to Facilitate XSEDE Operations, Planning and Analysis]

\subsection{Nagios}

Nagios is a web based Linux monitoring systems and it allows to monitor availability and response time of network services, usage of system resources like CPU load, RAM allocation etc., number of logged in users and so on. The main Nagios instance (server) collects information from Linux, BSD, Windows hosts or Cisco devices through Nagios clients (agents), and sees states of their services or processes in one place: Nagios web interface. Nagios generates a notification in case of any outage detected or any anomaly through wide range of alert methods such as e-mail, sms, chat messages and phone call notifications. And one more thing, Nagios monitors states but it doesn.t show any graphs like network interface usage etc.

\subsection{Cacti}
Cacti is a network monitoring tool using simple network management protocol (SNMP) and similar to other tools such as Nagios and Ganglia, it uses RRDtool as a DBMS and a visualization graphical tool. Since it supports polling monitoring data via shell scripts like php or c-based executable, it can be extended to measure other resources not only network traffic. It is also suitable for a hosting service with user-based management.

\subsection{Zabbix}

Zabbix is an open source monitoring not only for networks but also for servers using SNMP, IPMI, and JMX. The centralized server of Zabbix collects monitoring data through several Zabbix agents installed on desirable hosts and store them on the database to display and generate web-based reports when they are needed. Zabbix Agent which is deployed on a monitoring target obtains utilization data using various monitoring protocols and tools like SNMP, TCP, and ICMP. For the cloud monitoring, Zabbix active agent auto-registration helps monitoring cloud instances such as Amazon cloud, and OpenStack without configuring manually.

\subsection{Zenoss}

Zenoss (Zenoss Core) provides a unified resource management service which manages applications, networks, servers, and storage in terms of monitoring physical or virtual systems including the public, private and hybrid cloud. It is built on the Zope object-oriented web application server, and using RRDtool with MySQL as to store collected information using SNMP, SSH, WMI and log files e.g. syslog. Zenoss provides additional features with other monitoring mechanisms such as Perfmon, JMX, and VM API (e.g. VMware API) in the enterprise version which is based on the open-source core version. The one of the key features of Zenoss is Model-Driven Monitoring which is about automatic and dynamic discovery, configuration and monitoring. As a communication tool, Zenoss utilizes Twisted Perspective Broker (PB) instead of AMQP typed messaging system like RabbitMQ. They claims Twisted provides an asynchronous, event-driven with co-operative multi-tasking which is a deferred object.

\subsection{Rackspace Cloud Monitoring}

Rackspace Cloud Monitoring is an API driven monitoring system which allows administrators to use or create APIs depending on their needs which can send notifications to any device including mobile devices. This allows administrators to be on top of their Rackspace-hosted infrastructure which includes websites, protocols, and ports.

\section{System Design} \label{S:design}

FutureGrid Cloud Metrics pursues to provide an integrated accounting service which users and system administrators are able to obtain cloud usage data for various cloud platforms such as Eucalyptus, OpenStack, and Nimbus and so on. The usage information will cover several aspects like billing, auditing, monitoring, and accounting systems. Parsing log files is a main process for collecting and storing information regarding the utilization of virtual machine (VM) instances and service nodes or clusters. The current development focuses on:

\begin{itemize}
 \item A parsing tool of log messages
 \item A command-line interface to explore the cloud usage data
 \item A visualization to help understand usage data
 \item A REST Service to support external services
\end{itemize}

We have observed Eucalyptus generates resource usage information via log messages and OpenStack Essex stores virtual instances information to database. We have an idea for gathering resource utilization data using the log messages and database and for incorporating the data into one place. As a first step, we have implemented a log parsing tool for Eucalyptus to collect metering values and have provided a command line tool to obtain statistical results. For better presenting of numerical values and relationships with other metrics, we adopted charting libraries and they are helping us to provide succinct explanation for historical and real-time data. Figure~\ref{F:fig1} shows a conceptual view as to how Cloud Metrics works on IaaS.

\begin{figure}[h!] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/Picture1.pdf} 
  \caption{Overview of FutureGrid Cloud Metrics}\label{F:fig1} 
\end{figure} 


\section{Implementation} \label{S:implementation}

FG Cloud Metrics consists of two main parts: 1) a log parser and 2) an analyzer with visualization tools. We named the log parser as fg-parser which is a python script executable on Unix/Linux command. fg-parser reads and examines log messages of cloud platforms to collect metrics values and stores the values into a database system using a python dictionary data type. fg-analyzer takes the role of measuring usage data and displaying output in a graphical way. We assume every measured data is stored in the database, fg-analyzer loads the database and be ready to calculate metrics when a user specifies on the python cmd command line framework. fg-analyzer line-oriented interpreters allow the user to describe desired metrics and help to generate graphical output in various chart types. At this time, fg cloud metric supports Eucalyptus 2.0, and 3.0 and OpenStack except Nimbus, and OpenNebula.

\subsection{Log Parser}

fg-parser is an executable python script on Linux/Unix shell. It gets a path of log files as an input or a standard input as well. There are fixed templates to parse log messages using regular expressions and they are important for that what type of log events will be collected and how to be parsed to avoid parsing errors that cause missing events. We examined log messages of eucalyptus and realized eucalyptus generates detailed instance information using print\_ccInstance( function in debug logging mode. So our fixed template for eucalyptus is parsing print\_ccInstance( events of logs and fg-parser collects metrical values such as userid, instanceid, start and end time of an instance, number of cpu cores, disks, and memories and so on.

\subsection{Metric analyzer}

fg-analyzer uses python cmd package to support command-line interpreters. It allows that a user describes desired data using basic commands, for example, set nodename india, and set analyze -M 05 -Y 2012. It also comes with graphical tools using external chart libraries such as Google Chart API, Highcharts, D3.js, and jQuery Sparkline.

\subsection{Data structure - Python Dictionary}

Python dictionary (dict) provides key-value pair data structure which might be easy to handle unordered objects with any immutable type. It also can be easily converted to JSON or backwards using json and simplejson packages.

\section{Results and Analyses} \label{S:result}

Based on the observation on FutureGrid, there is a different pattern between a research project and class work when they acquire cloud resources.  Resource allocation of academic coursework shows time dependent request patterns. It shows a surge when there is a class, a lab session, and a project. For example, the undergraduate course for Distributed Systems at Indiana University introduced IaaS in the class and used the IaaS platform for a class project. Figure~\ref{F:fig2} shows a spike in the class and variability until the project due. Research projects request VM instances in a bit more steady usage compared to the coursework. The Next Generation Sequencing (NGS) in the cloud project on FutureGrid shows relatively consistent resource allocation requested in Figure~\ref{F:fig3} With a certain period of time, vm instances of this project have been launched without unplanned spike requests. These examples show different patterns for requesting resources but both cases have a factor to predict loads. The class schedule and the monitoring and profiling data for applications can be used to measure the amount of resources and identify incoming requests. In paid cloud platforms such as AWS, GCE, and Azure, understanding these patterns for provisioning is important to bring cost effectiveness over on-demand allocation. For example, Amazon EC2 Reserved Instances and Azure pre-pay plans may help reduce usage costs for periodic and planned workloads. These service plans simply provide discounts with an upfront payment. As long as a class and a project go as planned, cost saving chances are increased. 

\begin{figure}[h!] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig1.pdf} 
  \caption{IaaS Usage data for the Distributed System class at Indiana University*}\label{F:fig2} 
\end{figure} 


% * Based on the class schedule and metrics. Class schedule is here: http://salsahpc.indiana.edu/csci-p434-fall-2013/
% Metrics is here: http://129.79.49.94/accounting/reports/custom/p434fall13/FGResourceReport.pdf

\begin{figure}[h!] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig2.pdf} 
  \caption{VM count for Next Generation Sequencing (NGS) in the cloud project}\label{F:fig3} 
\end{figure} 

With the Gantt chart in Figure~\ref{F:fig4}, allocation activities are viewed for all virtual instances launched for the class. At the beginning of the class, the gaps between the start and completed dates of the vm instances are small but a large number of instances are initiated. Once the class is became operative,  running time for vm instances is getting longer and a smaller number of instances are requested compared to the beginning. This observation tells that academic projects require training sessions at the beginning of the project to get familiar with using infrastructure and to prepare environments by installing software and datasets.

\begin{figure}[h!] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig3.pdf} 
  \caption{Timeline for VM walltime}\label{F:fig4} 
\end{figure} 

Other observation is that resource usage for administrative purposes. Figure~\ref{F:fig5} describes that instructors consumed a large number of vCPU cores before class starts and small tests just before class projects. It indicates that the preparation of courses require extensive load testing on cloud resources to estimate compute capacity needed for applications.

 
\begin{figure}[h!] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig4.pdf} 
  \caption{Usage between instructors and students for vCPU cores}\label{F:fig5} 
\end{figure} 

During the semester, 25 hosts, 216 vCPUs and 600GB memories were reserved for the class since it required large virtual instances. In Figure~\ref{F:fig6} shows that the dedicated resources were being underutilized most time although the high volume requests had been made a few times including 273% overutilization on October 21th for testing and preparing.
  
\begin{figure}[h!] 
  \centering 
    \includegraphics[width=1.0\columnwidth]{images/fig5.pdf} 
  \caption{vCPU Utilization (approximation per hour)}\label{F:fig6} 
\end{figure} 

High Performance Computing (HPC) has been used to support parallel data processing of Big Data. With Figure~\ref{F:bigdata}, we can see Big Data projects have also requested HPC and other services to work on their projects. HPC is the most requested services to whom also requested Big Data services and IaaS cloud platforms are also requested many times followed by HPC. It explains that platform hybrid implementations are one of today.s trends for Big Data scientists and researchers. Regarding IaaS cloud platforms, there are three difference choices between OpenStack, Eucalyptus, and Nimbus. One observation from Figure~\ref{F:bigdata} is that OpenStack has taken Eucalyptus share since 2011 and became the most popular IaaS platform last year (2013). According to the recent report from RightScale [1], cloud competition is heating up not only in public cloud including Amazon Web Services (AWS) and Google Compute Engine (GCE), but also in private cloud. The report shows that OpenStack is the most popular cloud environment for private cloud users so the changes in Figure~\ref{F:bigdata} is understandable in terms of finding cloud alternatives.

\begin{figure}[h!]
  \centering
    \includegraphics[width=1.0\columnwidth]{images/bigdata.pdf} 
  \caption{Service changes for along with Big Data between 2010 and 2013}\label{F:bigdata} 
\end{figure} 

In HPC, 64 and 128 CPU cores per job are most popular job sizes in FutureGrid HPC in 2013 (See Figure~\ref{F:bigdatainhpc}). 24\% and 14\% of total wall time are for 64 and 128 cpu jobs. An extra large jobs (i.e. 512 CPU cores) has been intensively used in the last year. Compared to the previous year 2012, the request has been increased about 350\%. In early stage of FutureGrid between 2010 and 2011, tiny CPU jobs have been requested many times but in 2013, two thirds jobs are using more than 64 CPU cores.

\begin{figure}[h!]
  \centering
    \includegraphics[width=1.0\columnwidth]{images/bigdatainhpc.pdf} 
  \caption{Annual Wall Time Changes for Job Size in HPC between 2010 and 2013}\label{F:bigdatainhpc} 
\end{figure} 

\subsection{Pricing Comparison}

Comparing pricing of the cloud is complicated and may lead to false analogy because each cloud provider offers various services with different performance. The pricing comparison, however, is important when people start to consider adopting cloud services among a lot of selections from different providers. In the comparison, important criteria are revealed through its pricing table. For example, there are a range of service offered, a size of available systems, costs, discounts and benefits such as technical support, and development tools. Amazon AWS, Windows Azure, Google Compute Engine, HP Cloud, IBM and Rackspace are compared. Pricing is scenario based. It can't be simply compared with numbers. GCE looks cheaper than other competitors, but others have more options to save a cost. For example, a pay-ahead model provides a discount for same instances, and a spot instance also provides a way of saving entire cost for task intensive workloads in a small amount of time. In Table~\ref{T:tab0}, different price tags for virtual machine instances are described. With the comparison of the smallest vm instance which is 1 virtual core, 600-768MB memory and no storage option, we can see most IaaS service providers have similar pricing charts.

\begin{table*}[h!]
%\caption{Pricing chart for instances from AWS, GCE, and Azure \newline * China (Beijing) region will be available in early 2014, and GovCloud region is also included.}\label{T:tab0}
\caption{Pricing chart for instances from AWS, GCE, and Azure}\label{T:tab0}
\begin{tabular}{l|l|l|l}
     &	Billing granularity &	Price &	Variation for Price \\
  \hline
AWS &	By hour	& \$0.02 &	10 regions*, 6 platforms \\
GCE &	By minute, with a minimum of 10 minutes &	\$0.019  &	2 regions (Us, Europe) \\
Azure &	By minute, No minimum, No billing for less than 5 minutes & \$0.02 &	6 regions, 5 platforms \\
\end{tabular}
\end{table*}

\subsubsection{Example of Pricing Comparison}

We tried to apply each pricing model; Amazon AWS, Google Compute Engine, Microsoft Azure; to the usage data of class (P434 distributed systems at Indiana University), to compare cost estimate of cloud resource. Google Compute Engine is the least expensive and 16\% lower than Amazon AWS. It is mostly because of that Google has 10\% discount pricing chart compared to AWS. We observed that a minute basis charge is only 3.3\% less expensive for this class. Some restrictions and offers such as Google's 10-minute minimum charge and Azure's less 5-minute free of charge are relatively small amount of a discount or an extra charge. Google's 10-minute minimum charge asks 0.18\% extra charge to the class, Azure provides 0.05\% discount through their less 5-minute free of charge. Amazon only has an hourly based pricing model, while Google Compute Engine and Windows Azure offer a minute basis charge for use of virtual machine instances. Three types of instances (small/medium/large) had been used for its coursework and projects and usage of virtual machine instances was only calculated without network and storage usage. Table~\ref{T:tab1}, ~\ref{T:tab2} shows pricing comparison to the class.

\begin{table*}[h!]
\caption{Usage data to the class}\label{T:tab1}
\begin{tabular}{l|l|l|l|l|l}
Instance types & Instance count & Hour basis & Minute basis & Google 10mins minimum charge & Azure 5mins free \\
  \hline
small & 165 & 37,140 & 29,622 & 29,875 &29,582 \\
medium & 6 & 16,080 & 15,891 & 15,891 & 15,891 \\
large & 490 & 649,860 & 629,969 & 631,047 & 629,667 \\
  \hline \hline
Total & 661 & 703,080 & 675,482 & 676,813 & 675,140 \\
\end{tabular}
\end{table*}

%* Instance types are not same. Chosen by a similarity of vCPU and Memory
%** Captured by January, 2014

\begin{table*}[h!]
\caption{Pricing comparison to the class}\label{T:tab2}
\begin{tabular}{l|l|l|l|l}
Service & Cost Estimate & Pricing (Small/Medium/Large) & Restriction \\
 \hline
AWS & \$2,668.74  & \$0.06 / \$0.12 / \$0.24 per hour (US East Region; Linux) & Hour basis charge\\
GCE & \$2,231.54  & \$0.054 / \$0.104 / \$0.207 per hour (US Region; Linux) & Minute basis charge with 10-minute minimum\\
Azure & \$2,580.03  & \$0.06 / \$0.12 / \$0.24 per hour (Linux) & Minute basis charge with 5 less minute free\\
\end{tabular}
\end{table*}


\section{Summary}

We hope this activity provides a way of understanding performance and resource utilization across system and application layers. Cloud users can suffer performance degradation in a pool of shared resources, and monitoring physical resources is not enough to mitigate the degradation in the infrastructure. The classification of performance managements on the cloud provides an inside visibility to help identify the issues easily and finding solutions.

\section{Future Work}

We can think about rerouting VM instances to ensure scalable services by avoiding crowded zone. This cloud shifting may support relaxed management regarding load balancing of the cloud systems. The other potential work is probably that we can provide an indicator of cost-efficient leasing on the cloud based on the correlation data measured by this activity. Cost of using cloud can be reduced in many ways, including finding inexpensive cloud service providers, and using parallel processing technique such as MapReduce. Measuring correlation between physical and virtual resources could mean that we can find a spot in which reliable performance is guaranteed and it would be one of the main techniques to provide cost-efficient cloud renting.

In a sense of security, accounting is also able to provide some information for investigation of suspected security intrusions not only providing resource usage1 monitoring. Billing is another purpose of accounting.



\begin{sidewaystable*}
\caption{table 3}\label{T:tab3}

\begin{small}
\begin{tabular}{|p{2cm}|p{2cm}|p{1.5cm}|p{1.5cm}|p{2cm}|p{1cm}|p{1.5cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
Provider & Charging & Cost 1vCPU/hour	   & Cost 1GB/hour & OS & Max vCPU & Memory min - max &\# of instance types & Discount program & Free allowance\\
\hline
\hline
Aws & hourly & \$0.04  & \$0.02  & Linux & 32 & 615MB - & 22 & spot instance;  & \$100 for educators and student\\
    &  	     &         &  	 & Windows +14-56\%   	&    & 244GB    &       & reserved instances & Grant for researcher, AWS educated grant program\\
    &  	     &         &  	 & Asia + 25\% 		&    & 		       &       &  	  	    & \\
\hline
Google Compute Engine & 10 minutes + & \$0.08  & \$0.01  & Linux (Debian; CentOS) & 16 & 600MB - & 1- & n/a & Google app reward programs\\
 & every minute after that &  &  & (RHEL; SUSE premium operating systems) *** &  & 104GB & (4 high cpu + 4 high memory + 2 small + 5 standard) &  & \$1000 for educator\\
 &  &  & Europe + 4.5\% - 27\%  &  &  &  &  &  & \$60;000 for research project\\
\hline 
IBM CloudLayer (by Softlayer) & monthly & \$0.50  & varies & Linux;  & 16 & 1GB  & Build your own cloud server offers customized options &  & one month trial for 1 vcpu + 1gb memory + 25 storage\\
\hline
 & hourly & to &  & Windows + \$0.05 to &  & -  &  &  & \\
 &  & \$0.10  &  &               \$0.10 / hour &  & 64GB &  &  & \\
\hline 
HP cloud & hourly & \$0.02  & \$0.02  & Linux; Windows; SUSE & 16 & 1GB  & 11 (8 standard + 3 memory intensive) &  & \$300 free trial for 90 days (\$100 for each month)\\
 &  &  &  & (windows: 10-200\% extra charge; &  & -  &  &  & \\
 &  &  &  & SUSE: 4\% - 200\% extra charge) &  & 120GB &  &  & \\
\hline 
Microsoft Azure & Free first 5 minutes & \$0.05  & \$0.02 (approx.) & Linux;  & 8 & 768MB -  & 8 (A0-A7) & 6-Month; 12-month pre-pay membership & \$200 free trial of first month\\
 &  &  & Windows is expensive 30-50\% more than linux & Windows + 30-50\%  &  & 56GB &  &  & \\
\hline 
Rackspace & minute &  & varies & Linux; Windows, (windows: 25\% extra charge) & 32 & 1GB - 120GB  & 9 & Volume discount (4\% to 20\% for spending over \$5;000 - \$ 10; 000 per month; 8\% for \$10;001 - 30;000; 12\% for \$30;001 - \$50;000) Commitment discount (4\% to 40\%) Prepayment discount with commitment (7\% to 55\%)& \$300 developer discount (\$50 each for six months)\\
\hline
\end{tabular}
\end{small}
\end{sidewaystable*}


% Provider	Charging	Cost
% 1 vCPU /hour	Cost
% 1 GB
% /hour	OS	Max vCPU	Memory min - max	\# of instance types	Discount program	Free allowance
% Aws
% 	hourly	\$0.04
% 	$0.01927	Linux
% Windows +14-56% 
% Asia + 25%	32	615MB -
% 244GB	22	spot instance, 
% reserved instances	$100 for educator's student
% Grant for researcher
% AWS educated grant program
% Google Compute Engine	10 minutes +
% every minute after that	$0.0788
% 	$0.006636
% 
% Europe + 4.5% - 27% 	Linux (Debian, CentOS)
% (RHEL, SUSE premium operating systems) ***	16	600MB -
% 104GB	15
% (4 high cpu + 4 high memory + 2 small + 5 standard)	n/a	Google app reward programs
% $1000 for educator
% $60,000 for research project
% IBM CloudLayer (by Softlayer)	monthly
% hourly	$0.5
% to
% $0.10	varies	Linux, 
% Windows + $0.05 to
%               $0.10 / hour	16	1GB 
% – 
% 64GB	Build your own cloud server offers customized options		one month trial for 1 vcpu + 1gb memory + 25 storage
% HP cloud	hourly	$0.015	$0.015	Linux, Windows, SUSE
% (windows: 10-200% extra charge,
% SUSE: 4% - 200% extra charge)	16	1GB 
% – 
% 120GB	11 (8 standard + 3 memory intensive)		$300 free trial for 90 days ($100 for each month)
% Microsoft Azure	Free first 5 minutes
% 	$ 0.05	$0.02 (approx.)
% Windows is expensive 30-50% more than linux	Linux, 
% Windows + 30-50% 	8	768MB – 
% 56GB	8 (A0-A7)	6-Month, 12-month pre-pay membership	$200 free trial of first month
% Rackspace	minute		varies	Linux, Windows
% (windows: 25% extra charge)	32	1GB – 
% 120GB	9	Volume discount (4% to 20% for spending over $5,000 - $ 10, 000 per month, 8% for $10,001 - 30,000, 12% for $30,001 - $50,000)
% Commitment discount (4% to 40%)
% Prepayment discount with commitment (7% to 55%)	$300 developer discount ($50 each for six months)

\section{Citations}

just to show whats in cyberaide-metrics.bib

% \cite{www-c,www-b,www-a,www-abc,www-salsa-class,www-amzon-calculator2,www-o,www-n,www-m,www-l,www-k,www-j,www-i,www-h,www-g,www-f,www-w,www-v,www-u,www-t,www-s,www-r,www-q,www-p,www-e,www-d,www-amzon-calculator-1,www-amzon-calculator-2}
 

 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Acknowledgment 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
  
\section*{Acknowledgement} 
 
This material is based upon work supported in part by the National Science Foundation under Grant No. 0910812.
 
%\clearpage 
 
\bibliographystyle{IEEEtranS} 
%\bibliographystyle{abbrv} 
\bibliography{% 
bib/vonLaszewski-jabref,% 
bib/cyberaide-metric,%
bib/cyberaide-cloud}
%bib/image-refs,% 

%bib/python,% 
%tas.bib%
 
\end{document} 
 
 
